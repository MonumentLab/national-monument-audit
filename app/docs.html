<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>Monument Lab: National Monument Audit</title>
  <meta name="description" content="The National Monument Audit, led by Monument Lab, will assess the current monument landscape across the United States. ">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="icon" type="image/png" href="favicon.png">

  <link rel="stylesheet" href="css/vendor/normalize.css">
  <link rel="stylesheet" href="css/vendor/tocbot.css">

  <link rel="stylesheet" href="css/base.css">
  <link rel="stylesheet" href="css/docs.css">

</head>

<body>

  <div class="page">

    <nav id="toc" class="toc"></div>

    <main id="content" class="content">
      <h1>National Monument Audit: Technical Documentation</h1>

      <h2 id="introduction">Introduction</h2>

      <p>
      This document provides in-depth documentation of the data process of the 2021 National Monument Audit by Monument Lab. It is originally authored by the Audit’s Data Artist who architected the data workflow. This is made available for the Audit team, stakeholders, and members of the public who are interested in understanding how the Audit's "study set" was created from a technical point of view.
      </p>

      <h3 id="definitions">Definitions</h3>

      <ol>
        <li><strong>Data record</strong> - metadata about a specific cultural or historical object from a specific data source</li>
        <li><strong>Data field</strong> - a single piece of information in a data record, e.g. the name of the object or the date an object was created.</li>
        <li><strong>Data source</strong> - a verified organization, institution, or website that made available a set of digital data records representing cultural and historical objects</li>
        <li><strong>Study set</strong> - the Audit’s final and official dataset generated from the Audit's data sources with an attempt to include only records about monuments. This is not complete and has known gaps. It also inherits the various issues of its data sources. It attempts to exclude non-monument objects like buildings, bridges, streets, and place names.</li>
        <li><strong>Pre-study set</strong> - the complete set of data from data sources before excluding non-monument data records.</li>
        <li><strong>Data model</strong> - how a specific data record is structured. This is made up of multiple data fields such as date constructed, name, object type, subjects, location, etc.</li>
        <li><strong>Data ingest</strong> - the process of retrieving, filtering, and transforming raw data from data sources into the study set</li>
      </ol>

      <h3 id="scope">Scope</h3>

      <ol>
        <li>This document does <em>NOT</em> include the process for how the data sources were discovered, selected, or vetted. This will be articulated in the Audit itself, but is not in the scope of this document which focuses on how the data was processed after it was selected.</li>
        <li>This document outlines what data sources were used and which data fields were used for the study set.</li>
        <li>This document describes the data ingest process, i.e. how raw data from data sources were retrieved, filtered, and transformed into the study set.</li>
        <li>This document describes how a specific data record was determined to be a monument and thus part of the study set.</li>
        <li>This document describes the data model of an individual record in the study set.</li>
        <li>This document describes how geographical and temporal data was handled.</li>
        <li>This document describes how People were identified as honorees of their respective monuments.</li>
        <li>This document describes how duplicate records across different data sources were identified and handled.</li>
        <li>This document does NOT describe the codebase or give instructions for how to reproduce the data process with the existing or new data. You can visit the project's <a href="https://github.com/MonumentLab/national-monument-audit#national-monument-audit" target="_blank">Github code repository</a> for that information.</li>
      </ol>

      <h2 id="data-sources">Data sources</h2>

      <p id="stats-summary">For this audit, <strong>{{dataRecordTotal}}</strong> data records were retrieved and analyzed from <strong>{{dataSourceTotal}}</strong> data sources to generate a study set of <strong>{{totalMonuments}}</strong> ({{percentMonuments}}%) data records that are believed to represent monuments.</p>

      <h3 id="data-ingest">Data ingest process</h3>

      <p>Each data source provided publicly accessible digital records about cultural objects in a variety of formats. A large part of the work of the Audit was accessing, converting, parsing, and mapping that data into a single, normalized dataset. Here is the rough step-by-step data ingest process after a data source was identified.</p>

      <ol>
        <li>The data is downloaded manually. In some cases, the data was not readily available as a single downloadable file, so custom scripts were written to programmatically access and download them (in the case of data embedded in webpages or online maps).</li>
        <li>If applicable, the data was converted into a standard, usable format such as CSV, Shapefiles, etc.
          <ol>
            <li>This was sometimes done manually for things like geospatial files (like GeoJSON, KML, Shapefiles) that needed to be re-projected into a standard map projection.</li>
            <li>This was sometimes done programmatically in the case of HTML or PDF files that needed to be parsed in a customized fashion</li>
          </ol>
        </li>
        <li>Fields were manually mapped to the fields in the Audit's <a href="#data-model">data model</a> when relevant</li>
        <li>When applicable, the data was "enriched" using methods outlined later in this document, including:
          <ol>
            <li><a href="#geospatial-metadata">Geocoding locations</a> if addresses are provided, but lat/lon are not provided</li>
            <li>Extracting <a href="#honorees">names of people</a> that the object is possibly honoring</li>
            <li>Putting the object into specific <a href="#what-is-a-monument">object groups</a> (monument, building, structure, etc) and thematic groups (war, civil rights, etc) based on metadata provided where possible</li>
            <li>Identify if the object record is a <a href="#duplicates">duplicate</a> of another object record</li>
            <li>If the object is <a href="#honorees">honoring</a> a person, linking that person to a name authority and thus retrieving more information about that person (e.g. gender, ethnic group, birth date, etc)</li>
          </ol>
        </li>
      </ol>

      <p>For more technical details about this process you can visit the Audit's <a href="https://github.com/MonumentLab/national-monument-audit#national-monument-audit" target="_blank">Github code repository</a>.</p>

      <h3 id="full-data-sources">Full list of data sources</h3>

      <p>Click "show details" button to view which fields were used, how the fields were mapped, and any other notes about how the data was processed</p>

      <div id="data-sources-list" class="data-sources">Loading...</div>

      <h3 id="by-the-numbers">By the numbers</h3>

      <p>Share of records, pre-study set (before excluding non-monument data records) and study set (after excluding non-monuments)</p>

      <div id="data-sources-share-prestudy" class="data-container"></div>

      <div id="data-sources-share-study" class="data-container"></div>

      <p>Note: from here on in, <em>all numbers and charts will be based on the study set (monument data records only) and not non-monument records</em> unless otherwise noted</p>

      <h3 id="quirks">Data source quirks</h3>

      <p>While many of the data sources contain their own quirks, this section will highlight quirks in the larger, more visible data sources in the study set.</p>

      <ol>
        <li><a href="https://www.hmdb.org/" target="_blank">HMdb</a> is a crowd-sourced website and a major part of the study set. The major quirk of this data source is that <strong>they focus on <em>historical markers</em></strong> even if the marker describes an adjacent monument or memorial. So there are many records that are technically about a marker, but the marker exists to support and describe an adjacent monument. For example, this <a href="https://www.hmdb.org/m.asp?m=109322" target="_blank">entry about the Washington Monument</a> is one of <a href="https://www.hmdb.org/m.asp?m=70930" target="_blank">a</a> <a href="https://www.hmdb.org/m.asp?m=47332" target="_blank">few</a> HMdb entries that represent markers that surround and describe the Washington Monument. <strong>The monument itself does not have an entry on HMdb.</strong> So in this case, we attempt to merge all the markers about the Washington Monument on HMdb into a single record about the Washington Monument itself. We do this through the <a href="#duplicates">de-duplication process</a> as well as analyzing the captions under the images on HMdb.</li>

        <li>The Smithsonian Institution's <a href="https://americanart.si.edu/research/inventories/outdoor-sculpture" target="_blank">Save Outdoor Sculpture!</a> dataset is very comprehensive and very well-described. The major flaw in this dataset is that the latitude and longitude was not originally collected when this dataset was created, so it was subsequentially geocoded by the Smithsonian. <strong>This resulted in variably inaccurate geolocations</strong>. These can be off slightly or significantly. These are often represented by clusters of points on the map (likely the center of a city or town.) To get a sense of the extent of the problem, approximately half of the SoS data records are within a cluster of 10 or more records, which indicate that they are likely inaccurate coordinates. Of those inaccurate records, we attempt to do our own geocoding (based on their location description) which provides potentially better coordinates of about 40% of those records. All in all, if you see a record from SoS, <strong>use its location data with caution</strong>. It's likely best to look at it's address or location description to find it's real location. One other quirk in this dataset is that it was created between 1990 and 1995, which means <strong>it's missing monuments that have been erected or removed since 1995</strong>.</li>

        <li><a href="https://openstreetmap.org/" target="_blank">Open Street Map</a> provides information about <a href="https://wiki.openstreetmap.org/wiki/Tag%3Ahistoric%3Dmonument" target="_blank">historic monuments</a> and <a href="https://wiki.openstreetmap.org/wiki/Key:memorial" target="_blank">memorials</a> with highly accurate geographical precision. However, they use <a href="https://wiki.openstreetmap.org/wiki/Tag%3Ahistoric%3Dmonument" target="_blank">a very specific definition of a monument</a>  that can be intepreted inconsistently by Open Street Map contributors, resulting in <strong>objects that may not fit our definition of monument</strong>. Additionally, OSM records <strong>often do not contain much more metadata beyond the monument's name and location</strong>, so it is difficult to further categorize or validate. Usually we rely on the <a href="#duplicates">de-duplication process</a> to match OSM records to records from other data sources to get more metadata about them.</li>

        <li><a href="https://www.nps.gov/subjects/nationalregister/index.htm" target="_blank">National Register of Historic Places</a> is unique in that <strong>many data sources refer or build upon NRHP data records</strong>. This creates many potential duplication across data sources that build upon this data. When possible, we use the NRHP reference number to identify duplication of an NRHP across data sources before it is processed. Otherwise, we rely on the <a href="#duplicates">de-duplication process</a> to identify NRHP duplicates across data sources.</li>
      </ol>

      <h2 id="metadata">Metadata</h2>

      <p>Different data sources had different metadata available. The quality and consistency of the metadata also varied across the different data sources. This section will describe the inconsistencies and quirks of the source data and how data quality was addressed for the purposes of creating the study set.</p>

      <h3 id="geospatial-metadata">Geospatial metadata</h3>

      <p>Most data records have latitude and longitude available. In many cases the data source itself was in a geospatial format (e.g. <a href="https://en.wikipedia.org/wiki/GeoJSON" target="_blank">geojson</a>, <a href="https://en.wikipedia.org/wiki/Shapefile" target="_blank">shapefile</a>) but needed to be re-projected into a <a href="https://en.wikipedia.org/wiki/World_Geodetic_System" target="_blank">WGS 84 projection</a> using <a href="https://www.qgis.org/en/site/" target="_blank">QGIS</a>.</p>

      <!-- <div id="geo-latlon-available" class="data-container"></div> -->

      <p>However, there are many records that seem to have automatically generated their lat/lon coordinates. In some cases, this results in incorrect or inaccurate coordinates (e.g. placing it in the center of a state or city.) We attempt to filter these out by identifying clusters of data records that have the same lat/lon coordinate.</p>

      <!-- <div id="geo-latlon-approximate" class="data-container"></div> -->

      <p>In the case where there is not lat/lon coordinate, but there is a full street address, city, and state, we attempt to geocode these using <a href="https://www.openstreetmap.org/" target="_blank">OpenStreetMap</a>'s <a href="https://wiki.openstreetmap.org/wiki/Nominatim" target="_blank">Nominatim</a> geocoding service. Note we use this <em>only</em> when all three street address, city, and state are present. And we only accept the result if the coordinates are within the expected state.</p>

      <!-- <div id="geo-latlon-geocoded" class="data-container"></div> -->

      <p>How the geospatial information was obtained is reflected in a new data field that is generated called "Geo Type." This field has one of six values:</p>

      <ol>
        <li><strong>Exact coordinates provided</strong> - lat/lon coordinates are provided by data source and they are likely valid</li>
        <li><strong>Approximate coordinates provided</strong> - lat/lon coordinates are provided by data source but they are likely inaccurate; when possible (if street address is present), we attempt to geocode these ourselves. Otherwise, a warning appears in the interface for these likely inaccurate records.</li>
        <li><strong>Geocoded based on street address provided</strong> - lat/lon coordinates obtained by geocoding street address with <a href="https://wiki.openstreetmap.org/wiki/Nominatim" target="_blank">Nominatim</a> geocoding service</li>
        <li><strong>No valid geographic data provided</strong> - street address was provided, but no valid lat/lon coordinate could be found</li>
        <li><strong>No geographic data provided</strong> - neither lat/lon nor street address were provided by data source</li>
        <li><strong>Coordinates manually corrected from original</strong> - in rare cases, we manually correct lat/lon coordinate for those that we have confirmed inaccurate.</li>
      </ol>

      <div id="geo-latlon-by-type" class="data-container"></div>

      <h3 id="dates">Dates</h3>

      <p>Dates are present in about two-thirds of all the monument data records. Dates can be grouped into the following categories:</p>

      <ol>
        <li>Date constructed</li>
        <li>Date dedicated</li>
        <li>Date designated or listed as a landmark (local, state, national)</li>
        <li>Date removed <em>(rare)</em></li>
        <li>Date commissioned <em>(rare)</em></li>
      </ol>

      <p>Some things to note about dates:</p>

      <ol>
        <li>A data source may have none, one, or many of these dates present in their records. And sometimes dates may only be present in a subset of records within one data source.</li>

        <li>Dates come in all formats (e.g. 01-01-1900, Jan 1, 1900, 1900, 1901-1900). For the purposes of the Audit, all dates are <strong>normalized to a single year</strong> (e.g. "1900".) In the case of multiple dates (e.g. 1900-1901), the first one is taken.</li>

        <li>For the purposes of the Audit, we are only using <strong>date constructed and date dedicated</strong> for visualization purposes. And for the purpose of showing timelines, we combine date constructed and date dedicated into a single field called "Year Dedicated Or Constructed", however the individual fields ("Year Dedicated", "Year Constructed") are still available. In the case where date constructed and date dedicated are both available, "Year Dedicated Or Constructed" will be the "Year Dedicated."</li>
      </ol>

      <div id="dates-availability" class="data-container"></div>

      <h3 id="object-types">Object Types</h3>

      <p>Some data sources provide information about the physical form of the object. This can be very broad groups such as "Monument", "Building", or "Marker" or it can be very specific such as "Bench", "Fountain", "Relief." These values are not consistent across different data sources and the different data sources track these with different levels of strictness and specificity. When available, we heavily rely on this field when determining if an object is a monument (see section <a href="#what-is-a-monument">What is a monument?</a>).</p>

      <div id="object-types-availability" class="data-container"></div>

      <p><em>Note: the next two charts (object types and object groups) are based on the pre-study set, before filtering out monuments</em></p>

      <div id="object-types-by-type" class="data-container"></div>

      <p>We attempt to disambiguate and normalize object types into major groups, in particular, monument and non-monument groups. See <a href="#what-is-a-monument">What is a monument?</a> section.</p>

      <div id="object-groups-by-type" class="data-container"></div>

      <h3 id="honorees">Honorees</h3>

      <p>Very few data sources specify who or what is being honored:</p>

      <div id="honorees-availability" class="data-container"></div>

      <p>For records that do not have honoree information (most records), in order to understand who or what is being honored, we try to automatically determine this through a process of <a href="https://en.wikipedia.org/wiki/Named-entity_recognition" target="_blank">entity extraction</a> and <a href="https://en.wikipedia.org/wiki/Entity_linking" target="_blank">entity linking</a>. This process is roughly as follows:</p>

      <ol>
        <li>
          The text of the following fields are analyzed using a tool called <a href="https://spacy.io/" target="_blank">Spacy</a>: "Name", "Alternate Name", "Honorees", "Description"
        </li>

        <li>
          <a href="https://spacy.io/" target="_blank">Spacy</a> does many things like <a href="https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization" target="_blank"> tokenization</a> and part-of-speech tagging, but most importantly and relevantly, it does <a href="https://en.wikipedia.org/wiki/Named-entity_recognition" target="_blank">named-entitiy recognition</a>. This essentially tells if people, events, and organizations are included in the data fields we provide.

          <ul>
            <li>For example, in the following text:
              <code>
                Andrew Dickson White, 1832-1918, friend and counselor of Ezra Cornell, and with him associated in the founding of the Cornell University
              </code>
              The following named entities are expected:
              <ol>
                <li>Andrew Dickson White (PERSON)</li>
                <li>Ezra Cornell (PERSON)</li>
                <li>Cornell University (ORGANIZATION)</li>
              </ol>
            </li>
            <li>Spacy has a number of entity types available (see page 21 in <a href="" target="_blank">this document</a>), but we only use these:
              <ol>
                <li><strong>PERSON</strong> - People, including fictional</li>
                <li><strong>NORP</strong> - Nationalities or religious or political groups</li>
                <li><strong>ORGANIZATION</strong> - Companies, agencies, institutions, etc.</li>
                <li><strong>EVENT</strong> - Named hurricanes, battles, wars, sports events, etc.</li>
              </ol>
              And we currently only use "PERSON" in the search interface
            </li>
            <li>In order to do this, Spacy uses a large annotated corpus called <a href="https://catalog.ldc.upenn.edu/LDC2013T19" target="_blank">OntoNotes</a> that leverages a variety of sources such as news, conversational telephone speech, weblogs, usenet newsgroups, broadcast, and talk shows. It is important to note that <strong>any bias present in this corpus will be inherited</strong> by the entities that are recognized using Spacy.</li>
          </ul>
        </li>

        <li>
          After we receive named entities, we then attempt to <em>link</em> these entities to the specific "real-world" person, event, or organization. We do this by matching named entities against <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page" target="_blank">Wikidata</a> for those entities' corresponding entry. The advantages of this is that we can map multiple named entites ("Martin Luther King", "Martin Luther King, Jr.", "MLK") to a <a href="https://www.wikidata.org/wiki/Q8027" target="_blank">single specific person</a> and we can retrieve additional structured information about this person (e.g. date of birth, occupation, gender)

          <ul>
            <li>An important note: Just like Spacy, data about specific <strong>people on Wikidata inherit whatever biases the Wikidata contributors have</strong>.</li>
            <li>We are considering using the "ethnic group" (e.g. "African American") field when present in a Wikidata entry as a proxy for estimating the diversity or lack thereof of monumental representation. However, this is a very complex and fraught topic, so it requires explicit contextualization if used. Furthermore, if the person being represented is white, "ethnic group" is usually not present, i.e. white is the default-- another topic of discussion.</li>
          </ul>
        </li>
      </ol>

      <p>Note: We originally also analyzed plaque and marker text, but even though it helped identify more people, it resulting in too many false positives. For example, a civil war monument may quote Abraham Lincoln in the plaque, but may not be a monument about Lincoln himself. Therefore, in the case of Lincoln, we will only consider a monument honoring him if his name appears in the name of the monument, listed explicitly as an honoree, or contained within the monument description.</p>

      <div id="top-entities-people" class="data-container"></div>

      <!-- <div id="top-entities-events" class="data-container"></div> -->

      <h3 id="text">Plaque or marker text</h3>

      <p>About a third of the records contained the inscribed text that accompanies the object, such as the text on an embedded plaque or on an adjacent marker. This text is often very rich with a variety of formats (e.g. quotations, lists of names, narratives)</p>

      <div id="text-availability" class="data-container"></div>

      <h3 id="subjects">Subjects</h3>

      <p>Some sources categorized their objects in a variety of structured and undstructured ways. These would be referred to as fields like "Topic", "Tag", "Type", "Category", "Subject", etc. These are rarely consistent across data sources. Sometimes they contain broad topics (e.g. "Settlements & Settlers"), events ("U.S. Civil War"), groups of people ("Native Americans"), use types ("Cemeteries & Burial Sites"), or physical properties ("Abstract".) These fields are used when keyword searching, for determining if an object is a monument (see section <a href="#what-is-a-monument">What is a monument?</a>), and for determining if they fall under certain themes (e.g. War &amp; Weaponary.)</p>

      <div id="subjects-availability" class="data-container"></div>

      <h3 id="other-fields">Other fields of interest</h3>

      <p>There were other fields that may be useful for further research and visualization purposes. This includes creators (architect, sculptor, artist, foundry, etc), and sponsors.</p>

      <div id="misc-availability" class="data-container"></div>

      <h2 id="what-is-a-monument">What is a monument?</h2>

      <p>One of the central challenges of this Audit was idenfying which data records represented "monuments" in the conventional sense of the word. The Audit itself goes into great detail about how this was defined, so this document will avoid an attempt to define "monument" from a conceptual point of view. Instead, this section will walk through the practical process and application of the Audit's definition of "monument" as it relates to generating the final study set. This generally means describing the "rules" of what is a monument based on its metadata so that a computer script can categorize a data record as a monument or something else.  To start, some high-level points:</p>

      <ol>
        <li>Most data sources provided data records that were a mix of different types of objects such as markers, buildings, monuments, and structures. In other words, most sources did not simply provide a set of "monuments".</li>

        <li>Data records that represented monuments were often not marked as such, i.e. there was not a field that called it a "Monument" and may have instead been called "Object" or the physical form may not have been described at all.</li>

        <li>For those sources that called an object a "monument" either had its own definition of "monument" or did not provide a definition of "monument." The definitions of monuments across data sources differed.</li>
      </ol>

      <p>Given that, here is the high-level process for determining if something is or is not a monument:</p>

      <ol>
        <li>If a data source <em>explicitly</em> categorized something as a monument, we assume that it is a monument.
          <ul>
            <li>This is because a try to defer to the sources' data when possible rather than apply our own logic.</li>
            <li>Only a few of our data sources had fields that categorized their records in this way (E.g.
              <a href="https://wiki.openstreetmap.org/wiki/Tag%3Ahistoric%3Dmonument" target="_blank">OpenStreetMap</a>,
              <a href="https://www.slaverymonuments.org/items/browse" target="_blank">Contemporary Monuments to the Slave Past</a>,
              <a href="https://www.splcenter.org/20190201/whose-heritage-public-symbols-confederacy" target="_blank">Whose Heritage?</a>,
              <a href="https://pioneermonuments.net/explore/" target="_blank">Pioneer Monuments</a>,
              <a href="https://public-nps.opendata.arcgis.com/datasets/nps-points-of-interest-pois-web-mercator/data" target="_blank">National Park Service: Points of Interest</a>).</li>
            <li>This is done with the full awareness that the underlying objects may mis-categorized as "monuments" or may not exactly match our interpretation of "monuments."</li>
            <li>Known issue: OpenStreetMap data seems to contain "monuments" that we may not consider to be monuments based on our own definition; this may be because its definition differs from ours and it is crowd-sourced.</li>
          </ul>

        <li>If a data source does not explicitly tell us if something is a monument, we attempt to determine if something is a monument by looking for keywords in certain data fields. This process is roughly as follows:
          <ol>
            <li>A large number of records are filtered out based on keywords that indicate that they are part of different object groups such as <strong>markers</strong> ("Washington Slept Here historical marker"), <strong>buildings</strong> ("Washington School Compound"), <strong>streets</strong> ("Washington Street"), <strong>structures</strong> ("Washington's Canal"), <strong>sites</strong> ("George Washington Oak Tree Site"), or <strong>places</strong> ("Washington County"). This relies heavily on a record's <code>name</code> and <code>object type</code> fields.</li>
            <li>For an object or structure that calls itself a <strong>memorial</strong> (e.g. "Vietnam Veterans Memorial"), we consider this a monument, as long as it is not in already in a different object group (e.g. memorial highways, memorial high schools are not monuments.)</li>
            <li>For the records that remain, we then look for keywords that indicate their <strong>physical form</strong> (e.g. Bust, Statue, Cannon, etc.) and what or who it is representing. Generally speaking, we are looking for large, solid forms (obelisks, pyramids, statues) with some indication that they are honoring a person, group, or event. The criteria is roughly:
              <ol>
                <li>The object is part of certain physical forms that we consider monumental (obelisks, pyramids, statues, pillars, etc)</li>
                <li>The object is honoring a person, group, or event. E.g. the subject may contain words like "human figure" or "heroic" or "honoring", a historical name or event may be included in the name (e.g. "Harriet Tubman Statue")</li>
                <li>Conversely, we check for indications that the object are in a group we roughly consider artistic/abstract sculptures that do not honor a person, group, or event. In this case, the subject may contain "Abstract--Geometric" or "Plant--Flowers" with no mention or indication of an honoree or human figure.</li>
              </ol>
            </li>
            <li>For any records that remain, we consider them "Uncategorized" objects. These are likely records with little to no metadata other than its name and location, where the name is ambiguous (e.g. "World War II Roll of Honor" fits our definition or "honoring", but does not give an indication of what type of physical form it is).</li>
          </ol>
        </li>
      </ol>

      <h2 id="duplicates">Handling duplicates</h2>

      <p>Handling duplicate records across different data sources was a challenging area of work that is not completely solved. This refers to different records from different data sources that represent the same real-world object. We used a combination of object identifiers, geographic coordinates, and name fields to determine if two or more records were representing the same object. Here is the rough process:</p>

      <ol>
        <li>We look for records that have nearly the same latitude and longitude (within some radius)</li>
        <li>Within a group of such records, we analyze the name of the object. If the names are similar, then we consider them duplicates. We use a library called <a href="https://github.com/seatgeek/fuzzywuzzy" target="_blank">FuzzyWuzzy</a> (which uses <a href="https://en.wikipedia.org/wiki/Levenshtein_distance" target="_blank">Levenshtein distance</a>) to compare two names (after the two names are "normalized", i.e. lowercased, punctuation and parenthesized content removed). This allows for similar names (e.g. "Martin Luther King Civil Rights Memorial" and "Doctor Martin Luther King Junior Memorial") to be considered a match.</li>
        <li>Groups of duplicate records are then "merged" into a single, combined record. In the case of lists of values, such as "subjects" and "honorees", the lists are unioned with duplicates removed. In the case of single-value fields like name or construction date, more "official" sources (e.g. National Park Service, Smithsonian) took preference. For the case of latitude and longitude, certain sources that we believe have good geocoding (e.g. Open Street Map) took preference.</li>
      </ol>

      <div id="duplication-breakdown" class="data-container"></div>

      <p>There is one special case for duplication which are records in the <a href="https://www.nps.gov/subjects/nationalregister/index.htm" target="_blank">National Register of Historic Places</a>. There are a number of state and local data sources that contain NRHP records and crowd-sourced sources such as Open Street Map often build upon NRHP data. When possible, we use the NRHP reference number to identify duplication of an NRHP across data sources. This happens as a pre-process step, so redundant NRHP records are ignored before they are processed and entered into the study set unless they contain additional metadata (like in Open Street Map.)</p>

      <h2 id="study-set">The study set</h2>

      <p>As mentioned before, the Audit’s final and official dataset generated from the Audit's data sources is called the "Study set", which attempts to include only records about monuments. This is not complete and has known gaps. It also inherits the various issues of its data sources. It attempts to exclude non-monument objects like buildings, bridges, streets, and place names.</p>

      <h3 id="data-model">Data model</h3>

      <p>This dataset is composed of records that have a mix of fields taken verbatim from the data source and there are some fields that Monument Lab generated using those fields. Both unedited fields and generated fields are available within the study set.</p>

      <p>A full list of unedited fields taken directly from the data source are:</p>

      <table class="data-table">
        <tr><th>Field name</th><th>Description</th></tr>
        <tr><td>Name</td><td>The name of the monument</td></tr>
        <tr><td>Alternate Name</td><td>The alternate name or subtitle for this monument</td></tr>
        <tr><td>Vendor Entry Id</td><td>The identifier for this monument supplied by the data source</td></tr>
        <tr><td>Image</td><td>A URL of an image of the monument. In the case of multiple images, this is the first visible image</td></tr>
        <tr><td>Description</td><td>A long description of the monument</td></tr>
        <tr><td>Text</td><td>The plaque or marker text with formatting removed</td></tr>
        <tr><td>Source</td><td>The data source</td></tr>
        <tr><td>URL</td><td>The URL of the data source's monument record</td></tr>
        <tr><td>Street Address</td><td>The street address where the monument is located</td></tr>
        <tr><td>City</td><td>The city where the monument is located</td></tr>
        <tr><td>County</td><td>The county where the monument is located</td></tr>
        <tr><td>State</td><td>The state where the monument is located</td></tr>
        <tr><td>Latitude</td><td>The latitude of the location of the monument in degrees</td></tr>
        <tr><td>Longitude</td><td>The longitude of the location of the monument in degrees</td></tr>
        <tr><td>Location Description</td><td>An unstructured description of the location of the monument</td></tr>
        <tr><td>Year Dedicated</td><td>The year that the monument was dedicated</td></tr>
        <tr><td>Year Constructed</td><td>The year that the monument was constructed</td></tr>
        <tr><td>Year Dedicated Or Constructed</td><td>The year that the monument was dedicated or constructed; whichever is available first</td></tr>
        <tr><td>Object Types</td><td>List of the physical type(s) of the object (see <a href="#object-types">Object Types</a>)</td></tr>
        <tr><td>Use Types</td><td>List of what this object is used for (e.g. military, religious purposes)</td></tr>
        <tr><td>Subjects</td><td>List of open-ended categories or topics that this monument falls under (see <a href="#subjects">Subjects</a>)</td></tr>
        <tr><td>Honorees</td><td>List of who or what the monument is honoring (see <a href="#honorees">Honorees</a>)</td></tr>
        <tr><td>Creators</td><td>List of individuals involved in the construction/creation of this monument (architects, sculptors, foundries, etc)</td></tr>
        <tr><td>Sponsors</td><td>List of entities that sponsored this monument</td></tr>
        <tr><td>Dimensions</td><td>The physical dimensions of the monument (in a non-standard format)</td></tr>
        <tr><td>Material</td><td>A description of material(s) that make up this monument</td></tr>
        <!-- <tr><td>Status</td><td>A description of the monument's physical state (e.g. missing, removed, etc)</td></tr> -->
        <tr><td>Year Removed</td><td>The year that the monument was removed</td></tr>
        <tr><td>Wikipedia</td><td>Wikipedia identifier</td></tr>
      </table>

      <p>A full list of generated fields (not provided by the data source, but created by the Audit to enrich the provided data) are:</p>

      <table class="data-table">
        <tr><th>Field name</th><th>Description</th></tr>
        <tr><td>Id</td><td>The unique identifier of this monument (it is a mix of the Vendor Entry Id and the Source Id)</td></tr>
        <tr><td>Duplicate Of</td><td>The identifier of this record's "parent" record if it is a duplicate record</td></tr>
        <tr><td>Duplicates</td><td>A list of identifiers of child records if this record is a merged records from duplicate records</td></tr>
        <tr><td>Object Groups</td><td>The object group that this object belongs to (e.g. Marker, Monument, Building.) Merged records sometimes have multiple object groups since their child records may disagree. For merged records, if any one of its child records are a monument, it is considered a monument.</td></tr>
        <tr><td>Object Group Reason</td><td>A list of reasons why an object was assigned a particular object group</td></tr>
        <tr><td>Monument Types</td><td>The physical type(s) of monument (e.g. obelisk, bust, pyramid) this if it is in the Monument Object Group</td></tr>
        <tr><td>Entities People</td><td>A list of people that we believe this monument is honoring. See <a href="#honorees">Honorees</a> section</td></tr>
        <tr><td>Ethnicity Represented</td><td>The ethnic group of the person being honored. See <a href="#honorees">Honorees</a> section</td></tr>
        <tr><td>Gender Represented</td><td>The gender of the person being honored. See <a href="#honorees">Honorees</a> section</td></tr>
        <!-- <tr><td>Entities Events</td><td>A list of events that we believe this monument is honoring. See <a href="#honorees">Honorees</a> section</td></tr> -->
        <tr><td>Themes</td><td>The thematic category this monument falls into</td></tr>
        <tr><td>Geo Type</td><td>The type of latitude/longitude this record has. See <a href="#geospatial-metadata">Geospatial metadata</a> section</td></tr>
        <tr><td>County Geoid</td><td>The identifier of this record's county where the monument is located</td></tr>
      </table>

      <h3 id="accessing-the-data">Accessing the data</h3>

      <p>There are two main ways to access the data:</p>

      <ol>
        <li>Through the public online interface accessible through a desktop browser connected to the internet. This will be the way most people access the data since it provides a host of features that make it easy to search, browse, and filter through the study set. You can use the interface at this URL: <a href="https://monumentlab.github.io/national-monument-audit/app/map.html">monumentlab.github.io/national-monument-audit/app/map.html</a></li>

        <li>We also make the data available through data-downloads in .csv format which can be read by most spreadsheet software such as Excel or Google Sheets. This is for users who are comfortable working directly with large datasets or those who want to make their own interfaces or visualizations. You can download these files directly via the links below:</li>

        <ol>
          <li><a href="https://s3.amazonaws.com/national-monument-audit.monumentlab.com/data/compiled/monumentlab_national_monuments_audit_final_object_groups_monument.csv" target="_blank">Complete study set (monuments only) in .csv format</a> (59MB)</li>
          <li><a href="https://s3.amazonaws.com/national-monument-audit.monumentlab.com/data/compiled/monumentlab_national_monuments_audit_final.csv" target="_blank">Complete pre-study set (includes non-monuments) in .csv format</a> (415MB)</li>
        </ol>

        <em>Note that if a cell is a list, it will be delimited by a <code>|</code> (pipe) character. If a cell has no value, it will simply be an empty cell.</em>
      </ol>

      <h2 id="technical-process">The technical process</h2>

      <p>Please visit this <a href="https://github.com/MonumentLab/national-monument-audit#national-monument-audit" target="_blank">Github code repository</a> for technical details of the data process and interface</p>

    </main>

  </div>

  <script src="js/vendor/jquery-3.5.1.min.js"></script>
  <script src="js/vendor/underscore-min.js"></script>
  <script src="js/vendor/md5.js"></script>
  <script src="js/vendor/tocbot.min.js"></script>

  <script src="js/lib/dataTable.js"></script>
  <script src="js/lib/util.js"></script>

  <script src="js/docs.js"></script>

</body>

</html>
